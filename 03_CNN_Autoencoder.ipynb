{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"><sub>This notebook is distributed under the <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" target=\"_blank\">Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) license</a>.</sub></div>\n",
    "<h1>Hands on Machine Learning  <span style=\"font-size:12px;\"><i>by <a href=\"https://webgrec.ub.edu/webpages/000004/cat/dmaluenda.ub.edu.html\" target=\"_blank\">David Maluenda</a></i></span></h1>\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://atenea.upc.edu/course/view.php?id=71605\" target=\"_blank\">\n",
    "      <img src=\"https://github.com/dmaluenda/hands_on_machine_learning/raw/master/resources/upc_logo_49px.png\" width=\"130\"/>\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "  </td>\n",
    "  <td>   <!-- gColab -->\n",
    "    <a href=\"https://colab.research.google.com/github/dmaluenda/hands_on_machine_learning/blob/master/03_CNN_Autoencoder.ipynb\" target=\"_blank\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/hands_on_machine_learning/master/resources/colab_logo_32px.png\" />\n",
    "      Run in Google Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>   <!-- github -->\n",
    "    <a href=\"https://github.com/dmaluenda/hands_on_machine_learning/blob/master/03_CNN_Autoencoder.ipynb\" target=\"_blank\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/hands_on_machine_learning/master/resources/github_logo_32px.png\" />\n",
    "      View source on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>   <!-- download -->\n",
    "    <a href=\"https://raw.githubusercontent.com/dmaluenda/hands_on_machine_learning/master/03_CNN_Autoencoder.ipynb\"  target=\"_blank\"\n",
    "          download=\"03_CNN_Autoencoder\">\n",
    "      <img src=\"https://raw.githubusercontent.com/dmaluenda/hands_on_machine_learning/master/resources/download_logo_32px.png\" />\n",
    "      Download notebook\n",
    "      </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{III}$. Convolutional Neural Networks and Autoencoders (using Keras)\n",
    "\n",
    "Hands on \"Machine Learning on Classical and Quantum data\" course of\n",
    "[Master in Photonics - PHOTONICS BCN](https://photonics.masters.upc.edu/en/general-information)\n",
    "[[UPC](https://photonics.masters.upc.edu/en) +\n",
    "[UB](https://www.ub.edu/web/ub/en/estudis/oferta_formativa/master_universitari/fitxa/P/M0D0H/index.html?) +\n",
    "[UAB](https://www.uab.cat/en/uab-official-masters-degrees-study-guides/) +\n",
    "[ICFO](https://www.icfo.eu/lang/studies/master-studies)].\n",
    "\n",
    "Tutorial 3\n",
    "\n",
    "This notebook shows how to:\n",
    "- implement a neural network using the Tensorflow/Keras module\n",
    "- recognize/classify images with dense nets (supervised learning)\n",
    "- recognize/classify images with convolutional nets (supervised learning)\n",
    "- implement image denoising using pseudo-autoencoders (almost unsupervised learning)\n",
    "- generate images: U-net, GAN, cGAN and VAE (unsupervised learning)\n",
    "- anomaly detection with a 1D Autoencoder (unsupervised learning)\n",
    "- understand train, validation and test datasets\n",
    "- implement callbacks, like an automatic early stopper\n",
    "\n",
    "**References**:\n",
    "\n",
    "[1] [Machine Learning for Physicists](https://machine-learning-for-physicists.org/) by Florian Marquardt.<br>\n",
    "[2] [Keras](https://keras.io/getting_started/): a deep learning API written in Python.<br>\n",
    "[3] [Tensorflow](https://www.tensorflow.org/api_docs/python/tf): an open source machine learning platform.<br>\n",
    "[4] [Using neural nets to recognize handwritten digits](http://neuralnetworksanddeeplearning.com/chap1.html).<br>\n",
    "[5] [pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix): Image-to-image translation with a conditional GAN.<br>\n",
    "[6] VAE example on [Towards data science](https://towardsdatascience.com/variational-autoencoders-as-generative-models-with-keras-e0c79415a7eb).<br>\n",
    "[7] https://github.com/kartikgill/Autoencoders.<br>\n",
    "[8] https://github.com/dhanushkamath/VariationalAutoencoder. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#0.-Imports:-Basics-and-tensorflow\" data-toc-modified-id=\"0.-Imports:-Basics-and-tensorflow-0\">0. Imports: Basics and tensorflow</a></span></li><li><span><a href=\"#1.-Import-data\" data-toc-modified-id=\"1.-Import-data-1\">1. Import data</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Check-data\" data-toc-modified-id=\"1.1-Check-data-1.1\">1.1 Check data</a></span></li></ul></li><li><span><a href=\"#2.-Image-recognition-with-a-perceptron-NN-(Introduction-to-Keras)\" data-toc-modified-id=\"2.-Image-recognition-with-a-perceptron-NN-(Introduction-to-Keras)-2\">2. Image recognition with a perceptron NN (Introduction to Keras)</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Results-evaluation-after-1-epoch\" data-toc-modified-id=\"2.1-Results-evaluation-after-1-epoch-2.1\">2.1 Results evaluation after 1 epoch</a></span></li><li><span><a href=\"#2.2-Train-for-several-epochs\" data-toc-modified-id=\"2.2-Train-for-several-epochs-2.2\">2.2 Train for several epochs</a></span></li><li><span><a href=\"#2.3-[EXERCISE]:-Create-a-bigger-network-(more-layers-and-more-neurons-each)-and-try-to-improve-the-accuracy.\" data-toc-modified-id=\"2.3-[EXERCISE]:-Create-a-bigger-network-(more-layers-and-more-neurons-each)-and-try-to-improve-the-accuracy.-2.3\">2.3 [EXERCISE]: Create a bigger network (more layers and more neurons each) and try to improve the accuracy.</a></span></li></ul></li><li><span><a href=\"#3.-Image-recognition-with-a-CNN\" data-toc-modified-id=\"3.-Image-recognition-with-a-CNN-3\">3. Image recognition with a CNN</a></span></li><li><span><a href=\"#4.-Image-Denoiser-(almost-unsupervised-learning)\" data-toc-modified-id=\"4.-Image-Denoiser-(almost-unsupervised-learning)-4\">4. Image Denoiser (almost unsupervised learning)</a></span></li><li><span><a href=\"#5.-Generative-Adversarial-Neural-Networks-(pix2pix)\" data-toc-modified-id=\"5.-Generative-Adversarial-Neural-Networks-(pix2pix)-5\">5. Generative Adversarial Neural Networks (pix2pix)</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-[EXERCISE]-Apply-the-pix2pix-algorithm-to-a-certain-set-of-pair-images.\" data-toc-modified-id=\"5.1-[EXERCISE]-Apply-the-pix2pix-algorithm-to-a-certain-set-of-pair-images.-5.1\">5.1 [EXERCISE] Apply the pix2pix algorithm to a certain set of pair images.</a></span></li></ul></li><li><span><a href=\"#6.-Autoencoder-for-dimension-reduction\" data-toc-modified-id=\"6.-Autoencoder-for-dimension-reduction-6\">6. Autoencoder for dimension reduction</a></span></li><li><span><a href=\"#7.-Autoencoders-(unsupervised-training)\" data-toc-modified-id=\"7.-Autoencoders-(unsupervised-training)-7\">7. Autoencoders (unsupervised training)</a></span></li><li><span><a href=\"#8.-Timeseries-anomaly-detection-using-an-Autoencoder\" data-toc-modified-id=\"8.-Timeseries-anomaly-detection-using-an-Autoencoder-8\">8. Timeseries anomaly detection using an Autoencoder</a></span><ul class=\"toc-item\"><li><span><a href=\"#8.1-Load-the-data\" data-toc-modified-id=\"8.1-Load-the-data-8.1\">8.1 Load the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#8.1.1-Timeseries-data-without-anomalies\" data-toc-modified-id=\"8.1.1-Timeseries-data-without-anomalies-8.1.1\">8.1.1 Timeseries data without anomalies</a></span></li><li><span><a href=\"#8.1.2-Timeseries-data-with-anomalies\" data-toc-modified-id=\"8.1.2-Timeseries-data-with-anomalies-8.1.2\">8.1.2 Timeseries data with anomalies</a></span></li></ul></li><li><span><a href=\"#8.2-Prepare-training-data\" data-toc-modified-id=\"8.2-Prepare-training-data-8.2\">8.2 Prepare training data</a></span></li><li><span><a href=\"#8.3-Build-a-model\" data-toc-modified-id=\"8.3-Build-a-model-8.3\">8.3 Build a model</a></span></li><li><span><a href=\"#8.4-Train-the-model\" data-toc-modified-id=\"8.4-Train-the-model-8.4\">8.4 Train the model</a></span></li><li><span><a href=\"#8.5-Detecting-anomalies\" data-toc-modified-id=\"8.5-Detecting-anomalies-8.5\">8.5 Detecting anomalies</a></span><ul class=\"toc-item\"><li><span><a href=\"#8.5.1-Compare-recontruction\" data-toc-modified-id=\"8.5.1-Compare-recontruction-8.5.1\">8.5.1 Compare recontruction</a></span></li><li><span><a href=\"#8.5.2-Prepare-test-data\" data-toc-modified-id=\"8.5.2-Prepare-test-data-8.5.2\">8.5.2 Prepare test data</a></span></li></ul></li><li><span><a href=\"#8.6-Plot-anomalies\" data-toc-modified-id=\"8.6-Plot-anomalies-8.6\">8.6 Plot anomalies</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports: Basics and tensorflow\n",
    "`!pip install tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential # Sequential is the neural-network class\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input  # Let's see how to use it\n",
    "from tensorflow.keras.layers import Dense, GaussianDropout  # Fully connected\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPool2D  # for CNN\n",
    "from tensorflow.keras.layers import UpSampling2D, Flatten, Reshape  # For Autoencoders\n",
    "from tensorflow.keras import optimizers # to choose more advanced optimizers like 'adam'\n",
    "from tensorflow.keras.datasets import mnist  # dataset of handwritten numbers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']=300 # highres display\n",
    "\n",
    "# for subplots within subplots:\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# for nice inset colorbars: (approach changed from lecture 1 'Visualization' notebook)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition\n",
    "\n",
    "# for updating display \n",
    "# (very simple animation)\n",
    "from IPython.display import clear_output\n",
    "from time import time, sleep\n",
    "\n",
    "# Set up a random number generator with a fixed seed, so that\n",
    "# running this whole notebook repeatedly should always give\n",
    "# the same result (useful for debugging)\n",
    "rng = np.random.RandomState(23455)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data\n",
    "\n",
    "The loader for the MNIST image data was taken from Nielsen's online book,\n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html\n",
    "\n",
    "See specifically the following link, for downloading the MNIST image data (we only need the mnist.pkl.gz package inside the 'data' subdirectory; store it inside the present directory of the notebook):\n",
    "https://github.com/mnielsen/neural-networks-and-deep-learning/archive/master.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "mnist_loader\n",
    "~~~~~~~~~~~~\n",
    "\n",
    "taken from Nielsen's online book:\n",
    "http://neuralnetworksanddeeplearning.com/chap1.html\n",
    "\n",
    "\n",
    "A library to load the MNIST image data.  For details of the data\n",
    "structures that are returned, see the doc strings for ``load_data``\n",
    "and ``load_data_wrapper``.  In practice, ``load_data_wrapper`` is the\n",
    "function usually called by our neural network code.\n",
    "\"\"\"\n",
    "\n",
    "def load_data():\n",
    "    \"\"\" Return three datasets (train/val/test), each one being a tuple of\n",
    "         - numpy array of setSize x 28 x 28 x 1: Set of images\n",
    "         - numpy array of setSize x 1: Set of ground truth values\n",
    "        setSize is 50000 for the train set and 10000 for the val and test sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # get raw data: a tuple of two entries (train/test) each one \n",
    "    #  being also a tuple of two entries, one for a set of 28x28 images\n",
    "    #  and the other being a set of their corresponding integers\n",
    "    (train_val_X, train_val_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "    # to convert values from 0 to 255 into range 0. to 1.\n",
    "    train_val_X = train_val_X.astype('float32') / 255.\n",
    "    test_X = test_X.astype('float32') / 255.\n",
    "    \n",
    "    # adapt this if using `channels_first` image data format\n",
    "    train_val_X = np.reshape(train_val_X, (len(train_val_X), 28, 28, 1)) \n",
    "    test_X = np.reshape(test_X, (len(test_X), 28, 28, 1))\n",
    "    \n",
    "    train_X = train_val_X[:-10000]\n",
    "    val_X = train_val_X[-10000:]\n",
    "\n",
    "    train_y = train_val_y[:-10000]\n",
    "    val_y = train_val_y[-10000:]\n",
    "    \n",
    "    return (train_X, train_y), (val_X, val_y), (test_X, test_y)\n",
    "\n",
    "\n",
    "def flatten(dataset):\n",
    "    \"\"\" Takes a dataset and the image in it is flatten\n",
    "        The dataset is expected to be a tuple of two entries,\n",
    "        where the images are found in the first as a np array.\n",
    "    \"\"\"\n",
    "    image_set = dataset[0]\n",
    "    set_size = image_set.shape[0]\n",
    "    num_pixels = image_set.shape[1] * image_set.shape[2]\n",
    "    flattened_set = np.zeros([set_size, num_pixels])\n",
    "\n",
    "    for idx, item in enumerate(image_set):\n",
    "        flattened_set[idx, :] = image_set[idx].flatten()\n",
    "    \n",
    "    return flattened_set, dataset[1]\n",
    "\n",
    "\n",
    "def load_data_wrapper():\n",
    "    \"\"\" Return ``training_data``, ``validation_data`` and ``test_data``.\n",
    "           \n",
    "        Based on ``load_data``, but the ground truth value is encoded\n",
    "        as one hot vector.\n",
    "\n",
    "        In particular, ``train_data`` is a list containing 50,000\n",
    "        2-tuples ``(x, y)``:\n",
    "          ``x`` is a 784-dimensional numpy.ndarray containing the input image. \n",
    "          ``y`` is a 10-dimensional numpy.ndarray representing the unit vector \n",
    "                corresponding to the correct digit for ``x``.\n",
    "\n",
    "        The ``val_data`` and ``test_data`` are similar, except\n",
    "        each contains only 10,000 images.\n",
    "\n",
    "        Obviously, this means we're using slightly different formats for\n",
    "        the training data and the validation / test data.  These formats\n",
    "        turn out to be the most convenient for use in our neural network\n",
    "        code.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_d, val_d, test_d = load_data()\n",
    "    \n",
    "    training_data = flatten(train_d)\n",
    "    validation_data = flatten(val_d)\n",
    "    test_data = flatten(test_d)\n",
    "    \n",
    "    training_data = vectorize_targets(training_data)\n",
    "    validation_data = vectorize_targets(validation_data)\n",
    "    test_data = vectorize_targets(test_data)\n",
    "\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def vectorize_targets(dataset):\n",
    "    \"\"\" Takes a dataset and vectorize the targets (second entry of the tuple)\n",
    "        according to the ONE HOT encoder.\n",
    "    \"\"\"\n",
    "    num_samples = len(dataset[1])\n",
    "    targets = np.zeros([num_samples, 10])\n",
    "    for j in range(num_samples):\n",
    "        targets[j,:] = vectorized_result(dataset[1][j])\n",
    "        \n",
    "    return dataset[0], targets\n",
    "\n",
    "def vectorized_result(num):\n",
    "    \"\"\" Return a 10-dimensional unit vector with a 1.0 in the jth\n",
    "        position and zeroes elsewhere.  This is used to convert a digit\n",
    "        (0...9) into a corresponding desired output from the neural\n",
    "        network.  ONE HOT ENCODER\n",
    "    \"\"\"\n",
    "    e = np.zeros((10))\n",
    "    e[num] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((training_inputs, training_results),\n",
    " (validation_inputs, validation_results),\n",
    " (test_inputs, test_results)) = load_data_wrapper()\n",
    "\n",
    "num_samples = len(training_results)\n",
    "numpixels = training_inputs.shape[1]\n",
    "image_size = int(np.sqrt(numpixels))\n",
    "num_test_samples = len(test_results)\n",
    "\n",
    "print(\"num_samples:\", num_samples)\n",
    "print(\"numpixels:\", numpixels, f\"({image_size}x{image_size})\")\n",
    "print(\"num_test_samples:\", num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unflatten(flat_image, im_size=image_size):\n",
    "    return np.reshape(flat_image, [image_size, image_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"training_inputs.shape:\", training_inputs.shape)\n",
    "# psi=training_inputs - np.sum(training_inputs,axis=0) / num_samples\n",
    "\n",
    "idx_example = 35\n",
    "fig, axs = plt.subplots(1, 2, figsize=(3, 3))\n",
    "axs[0].imshow(unflatten(training_inputs[idx_example,:]))\n",
    "axs[0].set_title(f\"{idx_example}th training image\", fontsize=8)\n",
    "axs[0].axis('off')\n",
    "axs[1].imshow(unflatten(test_inputs[idx_example,:]))\n",
    "axs[1].set_title(f\"{idx_example}th test image\", fontsize=8)\n",
    "axs[1].axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(which):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(unflatten(test_inputs[which,:]),\n",
    "               interpolation='nearest', cmap='binary')\n",
    "    plt.show()\n",
    "    \n",
    "display_image(idx_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_array(rng=(8,8)):\n",
    "    numcolumns = rng[0]\n",
    "    BigImage = np.zeros([image_size*numcolumns, image_size*numcolumns])\n",
    "    \n",
    "    for j in range(rng[0]*rng[1]):\n",
    "        x = (j % numcolumns) * image_size\n",
    "        y = (j// numcolumns) * image_size\n",
    "        BigImage[x:x+image_size, \n",
    "                 y:y+image_size] = unflatten(test_inputs[j,:])\n",
    "        \n",
    "    plt.imshow(BigImage, interpolation='nearest', cmap='binary')\n",
    "    plt.show()\n",
    "    \n",
    "plt.figure(figsize=(1.5,1.5))\n",
    "display_image_array((8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image recognition with a perceptron NN (Introduction to Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a couple of perceptron networks (fully connected or dense neural network) with different shape (number of layers and layers size) by using [`tensorflow.keras.Sequencial`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) class and its methods [`add()`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#add) and [`compile()`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile). Check also classes [`tensorflow.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) and [`tensorflow.keras.optimizers.SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize a quite basic perceptron network\n",
    "def dense_net():\n",
    "    net = Sequential()\n",
    "    \n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Dense(30, input_shape=(numpixels,), activation='relu'))\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.SGD(learning_rate=1.0), \n",
    "                metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = dense_net()\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batchsize = 100\n",
    "batches = num_samples // batchsize - 1\n",
    "costs = np.zeros(batches)\n",
    "\n",
    "t0 = time()\n",
    "for j in range(batches):\n",
    "    costs[j] = net.train_on_batch(training_inputs[j*batchsize:(j+1)*batchsize,:], \n",
    "                                  training_results[j*batchsize:(j+1)*batchsize,:])[0]\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/step)\" % (t_done, t_done/batches))\n",
    "plt.figure(figsize=(3, 2))\n",
    "plt.plot(costs,linewidth=3)\n",
    "plt.legend(['Cost'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Results evaluation after 1 epoch\n",
    "\n",
    "Let's check the network performance by doing some predictions and comparing them to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_on(do_print=True, is_cnn=False):\n",
    "#     global test_inputs, test_results\n",
    "    global predictions_probs, predictions, true_labels\n",
    "    \n",
    "    if is_cnn:\n",
    "        inputs = np.reshape(test_inputs, \n",
    "                            [num_test_samples, image_size, image_size])\n",
    "    else:\n",
    "        inputs = test_inputs\n",
    "        \n",
    "    \n",
    "    predictions_probs = net.predict_on_batch(inputs)\n",
    "    predictions = np.argmax(predictions_probs, axis=1)\n",
    "    true_labels = np.argmax(test_results, axis=1)\n",
    "    \n",
    "    print_probs(predictions_probs)\n",
    "    print(\"Predictions:\", predictions)\n",
    "    print(\"True labels:\", true_labels)\n",
    "    \n",
    "    which=np.where(true_labels!=predictions)[0]\n",
    "    print(\"Wrong predictions: \", len(which)/num_test_samples*100, \"%\")\n",
    "    \n",
    "    for count, j in enumerate(which):\n",
    "        if count < 5:  # Show no more 20 images\n",
    "            display_image(j)\n",
    "            print(\"True: \", true_labels[j], \" - Predicted: \", predictions[j]) \n",
    "#             print(\"\\nWith prob.: \", prob2str(predictions_probs[j,:]))\n",
    "            print_probs(predictions_probs[j,:])\n",
    "    return which\n",
    "\n",
    "def print_probs(prob_array, numels=3):\n",
    "    prob2str = lambda ps: ' , '.join(f\"{p:.1f}\" for p in ps)\n",
    "    \n",
    "    if len(prob_array.shape) > 1:\n",
    "        probs_str0 = '\\n\\t'.join(prob2str(ps) for ps in predictions_probs[:numels])\n",
    "        probs_strL = '\\n\\t'.join(prob2str(ps) for ps in predictions_probs[-numels:])\n",
    "        probs_str = f\"\\n\\t{probs_str0}\\n\\t   ...\\n\\t{probs_strL}\"\n",
    "        suf = ''\n",
    "    else:\n",
    "        probs_str = prob2str(prob_array)\n",
    "        suf = ' '*8\n",
    "    \n",
    "    print(\"Predict. Prob.:\", probs_str)\n",
    "    print(suf+'( vals: '+''.join(f\" {v}    \" for v in range(10))+')')\n",
    "            \n",
    "wrongs = test_on()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train for several epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use the keras \"fit\" function to go through the whole data set many times \n",
    "#  ('epochs'), and even set aside some validation samples\n",
    "epochs = 30\n",
    "t0 = time()\n",
    "history=net.fit(training_inputs, training_results, batch_size=100, epochs=epochs, \n",
    "                validation_data=(validation_inputs, validation_results))\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/epoch)\" % (t_done, t_done/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histories(history_dict):\n",
    "    fig=plt.figure(figsize=(3,1.5))\n",
    "    for curve in ('categorical_accuracy', 'val_categorical_accuracy'):\n",
    "        plt.plot(history_dict[curve], linewidth=3, label=curve)\n",
    "\n",
    "    plt.legend(fontsize=6, loc='upper left')\n",
    "    plt.xlabel('epochs', fontsize=6)\n",
    "    plt.ylabel('score', fontsize=6)\n",
    "\n",
    "plot_histories(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# see which fraction of the test samples is classified incorrectly\n",
    "wrongs = test_on()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 [EXERCISE]: Create a bigger network (more layers and more neurons each) and try to improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image recognition with a CNN\n",
    "\n",
    "Let's do the same with a Convolutional Neural Network\n",
    "\n",
    "![https://miro.medium.com/max/1400/1*vkQ0hXDaQv57sALXAJquxA.jpeg](https://miro.medium.com/max/1400/1*vkQ0hXDaQv57sALXAJquxA.jpeg)\n",
    "![https://docs.ecognition.com/Resources/Images/ECogUsr/UG_CNN_scheme.png](https://docs.ecognition.com/Resources/Images/ECogUsr/UG_CNN_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the network\n",
    "def cnn_net():\n",
    "    net = Sequential()\n",
    "    # note: batch_input_shape is (batchsize,timesteps,data_dim)\n",
    "    net.add(Conv2D(input_shape=(image_size, image_size,1), filters=6, \n",
    "                   kernel_size=[5,5], activation='relu', padding='same'))\n",
    "    net.add(AveragePooling2D(pool_size=4))\n",
    "    net.add(Flatten())\n",
    "    net.add(Dense(10, activation='softmax'))\n",
    "    net.compile(loss='categorical_crossentropy', \n",
    "                optimizer=optimizers.Adam(learning_rate=0.1), \n",
    "                metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cnn_net()\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, _, _ = load_data()\n",
    "train_data = vectorize_targets(train_data)\n",
    "\n",
    "epochs = 3\n",
    "t0 = time()\n",
    "history=net.fit(train_data[0], train_data[1], batch_size=100,\n",
    "                epochs=epochs, validation_split=0.1)\n",
    "t_done = time() - t0\n",
    "\n",
    "print(\"Elapsed time: %.2f s (%.4f s/epoch)\" % (t_done, t_done/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histories(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# see which fraction of the test samples is classified incorrectly\n",
    "wrongs = test_on(is_cnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Denoiser (almost unsupervised learning)\n",
    "\n",
    "*Code based on [this Keras example](https://keras.io/examples/vision/autoencoder/)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_imgs, vl_imgs, te_imgs = load_data()\n",
    "\n",
    "train_X = tr_imgs[0]\n",
    "val_X = vl_imgs[0]\n",
    "test_X = te_imgs[0]\n",
    "\n",
    "noise_factor = 0.5\n",
    "# random values as noise source\n",
    "train_X_noisy = train_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_X.shape)  \n",
    "val_X_noisy = val_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=val_X.shape) \n",
    "test_X_noisy = test_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_X.shape) \n",
    "\n",
    "# to make values in the range of 0 to 1: values<0 -> 0 while values>1 -> 1.\n",
    "train_X_noisy = np.clip(train_X_noisy, 0., 1.)   \n",
    "val_X_noisy = np.clip(val_X_noisy, 0., 1.)\n",
    "test_X_noisy = np.clip(test_X_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(unflatten(train_X[i]), cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(unflatten(train_X_noisy[i]), cmap='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "x1 = Conv2D(4, (3, 3), activation='relu', padding='same')(Input_img)\n",
    "x1 = MaxPool2D( (2, 2), padding='same')(x1)\n",
    "x2 = Conv2D(8, (3, 3), activation='relu', padding='same')(x1)\n",
    "x2 = MaxPool2D( (2, 2), padding='same')(x2)\n",
    "x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(x2)\n",
    "encoded = MaxPool2D( (2, 2), padding='same')(x3)\n",
    "\n",
    "# decoding architecture\n",
    "x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x3 = UpSampling2D((2, 2))(x3)\n",
    "x2 = Conv2D(8, (3, 3), activation='relu', padding='same')(x3)\n",
    "x2 = UpSampling2D((2, 2))(x2)\n",
    "x1 = Conv2D(4, (3, 3), activation='relu')(x2)\n",
    "x1 = UpSampling2D((2, 2))(x1)\n",
    "decoded = Conv2D(1, (3, 3), padding='same')(x1)\n",
    "\n",
    "\n",
    "autoencoder = Model(Input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, \n",
    "                              verbose=1, mode='auto')\n",
    "\n",
    "a_e = autoencoder.fit(train_X_noisy, train_X,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_X_noisy, test_X),\n",
    "                callbacks=[early_stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to predict the reconstructed images for the original images...\n",
    "pred = autoencoder.predict(test_X_noisy)\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(unflatten(test_X[i]), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(unflatten(test_X_noisy[i]), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()\n",
    "\n",
    "# to visualize reconstructed images(output of autoencoder)\n",
    "plt.figure(figsize=(5,2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
    "    plt.yticks([]) # to remove y-axis\n",
    "    plt.grid(False) # to remove grid\n",
    "    plt.imshow(unflatten(pred[i]), cmap='gray') #display the image \n",
    "plt.tight_layout() # to have a proper space in the subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Check better results on [the original page](https://keras.io/examples/vision/autoencoder/)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generative Adversarial Neural Networks (pix2pix)\n",
    "\n",
    "Follow the links above to go to the pix2pix gCollab notebook from tensorflow team:\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/pix2pix\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />pix2pix gColab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />pix2pix GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/generative/pix2pix.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download pix2pix</a>\n",
    "  </td>\n",
    "</table>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the article on [ArXiv:1611.07004](https://click.endnote.com/viewer?doi=arxiv%3A1611.07004&token=WzMxMDY4NjcsImFyeGl2OjE2MTEuMDcwMDQiXQ.3nqHSEuMgHTrfoeMMT0LpfRBvmY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 [EXERCISE] Apply the pix2pix algorithm to a certain set of pair images.\n",
    "\n",
    "Save and download the gColab you worked on and upload to Attenea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Autoencoder for dimension reduction\n",
    "\n",
    "Code based on [this example on *Towards data science*](https://ekamperi.github.io/machine%20learning/2021/01/21/encoder-decoder-model.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST data set\n",
    "tr_imgs, vl_imgs, te_imgs = load_data()\n",
    "\n",
    "x_train = tr_imgs[0]\n",
    "x_val = vl_imgs[0]\n",
    "x_test = te_imgs[0]\n",
    "y_test = te_imgs[1]\n",
    "\n",
    "# Take a look at the dataset\n",
    "n_samples = 10\n",
    "idx = random.sample(range(x_train.shape[0]), n_samples)\n",
    "plt.figure(figsize=(15,4))\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(1, n_samples, i+1)\n",
    "    plt.imshow(x_train[idx[i]].squeeze());\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the dimension of the latent space (encoding space)\n",
    "latent_dim = 2\n",
    "\n",
    "# Images are 28 by 28\n",
    "img_shape = (x_train.shape[1], x_train.shape[2])\n",
    "\n",
    "encoder = Sequential([\n",
    "    Flatten(input_shape=img_shape),\n",
    "    Dense(192, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dense(latent_dim, name='encoder_output')\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(64, activation='sigmoid', input_shape=(latent_dim,)),\n",
    "    Dense(128, activation='sigmoid'),\n",
    "    Dense(img_shape[0] * img_shape[1], activation='relu'),\n",
    "    Reshape(img_shape)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestEncoder(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_test, y_test):\n",
    "        super(TestEncoder, self).__init__()\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.current_epoch = 0\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.current_epoch = self.current_epoch + 1\n",
    "        encoder_model = Model(inputs=self.model.input,\n",
    "                              outputs=self.model.get_layer('encoder_output').output)\n",
    "        encoder_output = encoder_model(self.x_test)\n",
    "        plt.subplot(4, 3, self.current_epoch)\n",
    "        plt.scatter(encoder_output[:, 0],\n",
    "                    encoder_output[:, 1], s=20, alpha=0.8,\n",
    "                    cmap='Set1', c=self.y_test[0:x_test.shape[0]])\n",
    "        plt.xlim(-9, 9)\n",
    "        plt.ylim(-9, 9)\n",
    "        plt.xlabel('Latent Dimension 1')\n",
    "        plt.ylabel('Latent Dimension 2')\n",
    "\n",
    "autoencoder = Model(inputs=encoder.input, outputs=decoder(encoder.output))\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "model_history = autoencoder.fit(x_train, x_train, epochs=12, batch_size=32,\n",
    "                                verbose=0,\n",
    "                                callbacks=[TestEncoder(x_test[0:500], \n",
    "                                                       y_test[0:500])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3.5,1.5))\n",
    "plt.plot(model_history.history[\"loss\"])\n",
    "plt.title(\"Loss vs. Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 40\n",
    "fake_sample = np.random.uniform(low=-20, high=20, size=(n_samples, 2))\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(n_samples):\n",
    "    plt.subplot(4, n_samples//4, i+1)\n",
    "    fake_encoding = np.array([fake_sample[i]])\n",
    "    fake_digit = decoder(fake_encoding).numpy().squeeze() \n",
    "    plt.imshow(fake_digit);\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Nplot = 21\n",
    "plt.figure(figsize=(15,15))\n",
    "idx = 0\n",
    "for ix in np.linspace(-9, 9, Nplot):\n",
    "    for iy in np.linspace(-9, 9, Nplot):\n",
    "        idx += 1\n",
    "        plt.subplot(Nplot, Nplot, idx)\n",
    "        fake_encoding = np.expand_dims(np.array([ix, iy]), 0)\n",
    "        fake_digit = decoder(fake_encoding).numpy().squeeze() \n",
    "        plt.imshow(fake_digit);\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Autoencoders (unsupervised training)\n",
    "\n",
    "Go to [`random_face_generator.ipynb` notebook](https://github.com/dhanushkamath/VariationalAutoencoder/blob/master/Variational_Autoencoder.ipynb).\n",
    "\n",
    "Play with https://generated.photos/face-generator/new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 8. Timeseries anomaly detection using an Autoencoder\n",
    "\n",
    "https://keras.io/examples/timeseries/timeseries_anomaly_detection/\n",
    "\n",
    "**Author:** [pavithrasv](https://github.com/pavithrasv)<br>\n",
    "**Date created:** 2020/05/31<br>\n",
    "**Last modified:** 2020/05/31<br>\n",
    "\n",
    "This script demonstrates how you can use a reconstruction convolutional autoencoder model to detect anomalies in timeseries data.\n",
    "\n",
    "### 8.1 Load the data\n",
    "\n",
    "We will use the [Numenta Anomaly Benchmark(NAB)](\n",
    "https://www.kaggle.com/boltzmannbrain/nab) dataset. It provides artifical\n",
    "timeseries data containing labeled anomalous periods of behavior. Data are\n",
    "ordered, timestamped, single-valued metrics.\n",
    "\n",
    "We will use the `art_daily_small_noise.csv` file for training and the\n",
    "`art_daily_jumpsup.csv` file for testing. The simplicity of this dataset\n",
    "allows us to demonstrate anomaly detection effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
    "\n",
    "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
    "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
    "df_small_noise = pd.read_csv(\n",
    "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")\n",
    "\n",
    "df_daily_jumpsup_url_suffix = \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
    "df_daily_jumpsup_url = master_url_root + df_daily_jumpsup_url_suffix\n",
    "df_daily_jumpsup = pd.read_csv(\n",
    "    df_daily_jumpsup_url, parse_dates=True, index_col=\"timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at the data. Check *Pandas* documentation: https://www.geeksforgeeks.org/python-pandas-dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_small_noise))\n",
    "print(df_small_noise)\n",
    "print(df_daily_jumpsup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the data\n",
    "\n",
    "#### 8.1.1 Timeseries data without anomalies\n",
    "\n",
    "We will use the following data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_small_noise))\n",
    "fig, ax = plt.subplots()\n",
    "df_small_noise.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.2 Timeseries data with anomalies\n",
    "\n",
    "We will use the following data for testing and see if the sudden jump up in the\n",
    "data is detected as an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Prepare training data\n",
    "\n",
    "Get data values from the training timeseries data file and normalize the\n",
    "`value` data. We have a `value` for every 5 mins for 14 days.\n",
    "\n",
    "-   24 * 60 / 5 = **288 timesteps per day**\n",
    "-   288 * 14 = **4032 data points** in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and save the mean and std we get,\n",
    "# for normalizing test data.\n",
    "training_mean = df_small_noise.mean()\n",
    "training_std = df_small_noise.std()\n",
    "df_training_value = (df_small_noise - training_mean) / training_std\n",
    "print(\"Number of training samples:\", len(df_training_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create sequences combining `TIME_STEPS` contiguous data values from the\n",
    "training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 288\n",
    "\n",
    "# Generated training sequences for use in the model.\n",
    "def create_sequences(values, time_steps=TIME_STEPS):\n",
    "    output = []\n",
    "    for i in range(len(values) - time_steps + 1):\n",
    "        output.append(values[i : (i + time_steps)])\n",
    "    return np.stack(output)\n",
    "\n",
    "\n",
    "x_train = create_sequences(df_training_value.values)\n",
    "print(\"Training input shape: \", x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Build a model\n",
    "\n",
    "We will build a convolutional reconstruction autoencoder model. The model will\n",
    "take input of shape `(batch_size, sequence_length, num_features)` and return\n",
    "output of the same shape. In this case, `sequence_length` is 288 and\n",
    "`num_features` is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = tf.keras.layers\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
    "        layers.Conv1D(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1D(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
    "        ),\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Train the model\n",
    "\n",
    "Please note that we are using `x_train` as both the input and the target\n",
    "since this is a reconstruction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot training and validation loss to see how the training went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Detecting anomalies\n",
    "\n",
    "We will detect anomalies by determining how well our model can reconstruct\n",
    "the input data.\n",
    "\n",
    "\n",
    "1.   Find MAE loss on training samples.\n",
    "2.   Find max MAE loss value. This is the worst our model has performed trying\n",
    "to reconstruct a sample. We will make this the `threshold` for anomaly\n",
    "detection.\n",
    "3.   If the reconstruction loss for a sample is greater than this `threshold`\n",
    "value then we can infer that the model is seeing a pattern that it isn't\n",
    "familiar with. We will label this sample as an `anomaly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train MAE loss.\n",
    "x_train_pred = model.predict(x_train)\n",
    "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
    "\n",
    "plt.hist(train_mae_loss, bins=50)\n",
    "plt.xlabel(\"Train MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Get reconstruction loss threshold.\n",
    "threshold = np.max(train_mae_loss)\n",
    "print(\"Reconstruction error threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5.1 Compare recontruction\n",
    "\n",
    "Just for fun, let's see how our model has recontructed the first sample.\n",
    "This is the 288 timesteps from day 1 of our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the first sequence is learnt\n",
    "plt.plot(x_train[0])\n",
    "plt.plot(x_train_pred[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5.2 Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_test_value = (df_daily_jumpsup - training_mean) / training_std\n",
    "fig, ax = plt.subplots()\n",
    "df_test_value.plot(legend=False, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "# Create sequences from test values.\n",
    "x_test = create_sequences(df_test_value.values)\n",
    "print(\"Test input shape: \", x_test.shape)\n",
    "\n",
    "# Get test MAE loss.\n",
    "x_test_pred = model.predict(x_test)\n",
    "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
    "test_mae_loss = test_mae_loss.reshape((-1))\n",
    "\n",
    "plt.hist(test_mae_loss, bins=50)\n",
    "plt.xlabel(\"test MAE loss\")\n",
    "plt.ylabel(\"No of samples\")\n",
    "plt.show()\n",
    "\n",
    "# Detect all the samples which are anomalies.\n",
    "anomalies = test_mae_loss > threshold\n",
    "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
    "print(\"Indices of anomaly samples: \", np.where(anomalies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Plot anomalies\n",
    "\n",
    "We now know the samples of the data which are anomalies. With this, we will\n",
    "find the corresponding `timestamps` from the original test data. We will be\n",
    "using the following method to do that:\n",
    "\n",
    "Let's say time_steps = 3 and we have 10 training values. Our `x_train` will\n",
    "look like this:\n",
    "\n",
    "- 0, 1, 2\n",
    "- 1, 2, 3\n",
    "- 2, 3, 4\n",
    "- 3, 4, 5\n",
    "- 4, 5, 6\n",
    "- 5, 6, 7\n",
    "- 6, 7, 8\n",
    "- 7, 8, 9\n",
    "\n",
    "All except the initial and the final time_steps-1 data values, will appear in\n",
    "`time_steps` number of samples. So, if we know that the samples\n",
    "[(3, 4, 5), (4, 5, 6), (5, 6, 7)] are anomalies, we can say that the data point\n",
    "5 is an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data i is an anomaly if samples [(i - timesteps + 1) to (i)] are anomalies\n",
    "anomalous_data_indices = []\n",
    "for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):\n",
    "    if np.all(anomalies[data_idx - TIME_STEPS + 1 : data_idx]):\n",
    "        anomalous_data_indices.append(data_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overlay the anomalies on the original test data plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_daily_jumpsup.iloc[anomalous_data_indices]\n",
    "fig, ax = plt.subplots()\n",
    "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
    "df_subset.plot(legend=False, ax=ax, color=\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
